{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF0YSQGId3fl",
        "outputId": "9c574dcc-4f0c-40d3-d3d3-66fbd7dc1187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data successfully extracted and saved to full_ehome_dsl_data.json\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "# Load the HTML content\n",
        "with open(\"Pasted_Text_1750885383620.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    html_content = f.read()\n",
        "\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Extract Title\n",
        "# =============================\n",
        "title_section = soup.find('section', id=\"for_table\")\n",
        "if title_section:\n",
        "    title_parts = title_section.find_all('h3', class_='ff-suissintl-bold')\n",
        "    title = \" \".join([h3.get_text(strip=True) for h3 in title_parts])\n",
        "else:\n",
        "    title = \"باقات eHome DSL\"\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Extract DSL Packages\n",
        "# =============================\n",
        "def extract_dsl_packages():\n",
        "    dsl_data = []\n",
        "\n",
        "    # Extract data unit (e.g. جيجابايت)\n",
        "    data_unit_elem = soup.find('p', class_='ff-suissintl-bold fs-16')\n",
        "    data_unit = \"جيجابايت\"\n",
        "    if data_unit_elem:\n",
        "        data_text = data_unit_elem.get_text(strip=True)\n",
        "        if \"جيجابايت\" in data_text:\n",
        "            data_unit = \"جيجابايت\"\n",
        "\n",
        "    # Extract currency unit (e.g. جنيه)\n",
        "    currency_unit_elem = soup.find('sub', class_='plan-currency')\n",
        "    currency_unit = \"جنيه\"\n",
        "    if currency_unit_elem:\n",
        "        currency_text = currency_unit_elem.get_text(strip=True)\n",
        "        if \"جنيه\" in currency_text:\n",
        "            currency_unit = \"جنيه\"\n",
        "\n",
        "    speed_tabs = {\n",
        "        \"one_tab\": \"30 Mbps\",\n",
        "        \"two_tab\": \"70 Mbps\",\n",
        "        \"three_tab\": \"100 Mbps\",\n",
        "        \"four_tab\": \"200 Mbps\"\n",
        "    }\n",
        "\n",
        "    for tab_id, speed in speed_tabs.items():\n",
        "        tab = soup.find('div', {'id': tab_id})\n",
        "        if not tab:\n",
        "            continue\n",
        "\n",
        "        rows = tab.find_all('tr')\n",
        "        for i, row in enumerate(rows):\n",
        "            cells = row.find_all('td')\n",
        "\n",
        "            if len(cells) == 0:\n",
        "                continue\n",
        "\n",
        "            for j, cell in enumerate(cells):\n",
        "                try:\n",
        "                    name_elem = cell.find('h5', class_='plan-name')\n",
        "                    price_elem = cell.find('h5', class_='plan-price')\n",
        "\n",
        "                    if not name_elem or not price_elem:\n",
        "                        continue\n",
        "\n",
        "                    data_value = name_elem.get_text(strip=True).split()[0]\n",
        "                    price_value = price_elem.get_text(strip=True).split()[0]\n",
        "\n",
        "                    # Use dynamic units\n",
        "                    data_with_unit = f\"{data_value} {data_unit}\"\n",
        "                    price_with_unit = f\"{price_value} {currency_unit}\"\n",
        "\n",
        "                    benefit = \"\"\n",
        "                    if i + 1 < len(rows):\n",
        "                        benefit_cells = rows[i + 1].find_all('td')\n",
        "                        if j < len(benefit_cells):\n",
        "                            benefit = benefit_cells[j].get_text(strip=True)\n",
        "\n",
        "                    validity = \"شهر\"\n",
        "\n",
        "                    dsl_data.append({\n",
        "                        \"speed\": speed,\n",
        "                        \"data_gb\": data_with_unit,\n",
        "                        \"price_egp\": price_with_unit,\n",
        "                        \"benefit\": benefit,\n",
        "                        \"validity\": validity\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "    return dsl_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Extract Terms and Conditions\n",
        "# =============================\n",
        "def extract_terms_and_conditions():\n",
        "    terms_sections = soup.find_all('section', id=\"for_features_and_terms\")\n",
        "    terms_list = []\n",
        "\n",
        "    for section in terms_sections:\n",
        "        title_div = section.find('div', class_='for__sectionTitles')\n",
        "        if title_div:\n",
        "            full_title = ' '.join([h.get_text(strip=True) for h in title_div.find_all('h3')])\n",
        "            if \"الشروط و الاحكام للباقة\" in full_title:\n",
        "                items = section.select(\".col-sm-12.col-md-6.col-lg-4.my-3.d-flex\")\n",
        "                for item in items:\n",
        "                    span = item.find('span')\n",
        "                    p_tag = item.find('p', class_='fs-16')\n",
        "                    if span and p_tag:\n",
        "                        number = span.get_text(strip=True)\n",
        "                        text = p_tag.get_text(strip=True)\n",
        "                        terms_list.append({\"number\": number, \"text\": text})\n",
        "                break\n",
        "\n",
        "    return terms_list\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Extract Favorite Packages (Streaming, Gaming, Off-Peak)\n",
        "# =============================\n",
        "def extract_favorite_packages():\n",
        "    def clean_numeric_value(value):\n",
        "        \"\"\"Extract digits from string.\"\"\"\n",
        "        return ''.join(filter(str.isdigit, value))\n",
        "\n",
        "    result = {\n",
        "        \"section_title\": \"الباقات المفضلة\",\n",
        "        \"packages\": {\n",
        "            \"streaming\": [],\n",
        "            \"gaming\": [],\n",
        "            \"off_peak\": []\n",
        "        }\n",
        "    }\n",
        "\n",
        "    tabs = {\n",
        "        \"streaming-tab\": \"streaming\",\n",
        "        \"social-tab\": \"gaming\",\n",
        "        \"off-peak-tab\": \"off_peak\"\n",
        "    }\n",
        "\n",
        "    tab_titles = {\n",
        "        \"streaming\": \"المشاهدة\",\n",
        "        \"gaming\": \"الألعاب\",\n",
        "        \"off_peak\": \"خارج أوقات الذروة\"\n",
        "    }\n",
        "\n",
        "    # Scrape dynamic note\n",
        "    note_element = soup.find('p', class_='plan-hint mediumGrey-color')\n",
        "    if note_element:\n",
        "        dynamic_note = note_element.get_text(strip=True).replace(\"يمكنكاضافه\", \"يمكنك اضافه\").replace(\"تلقائياكل\", \"تلقائيا كل\")\n",
        "    else:\n",
        "        dynamic_note = \"يمكنك اضافه الباقه مره واحده او تجدد تلقائيا كل 30 يوم\"\n",
        "\n",
        "    # Data unit\n",
        "    data_unit_elem = soup.find('p', class_='ff-suissintl-bold fs-16')\n",
        "    data_unit = \"جيجابايت\"\n",
        "    if data_unit_elem:\n",
        "        data_text = data_unit_elem.get_text(strip=True)\n",
        "        if \"جيجابايت\" in data_text:\n",
        "            data_unit = \"جيجابايت\"\n",
        "\n",
        "    # Currency unit\n",
        "    currency_unit_elem = soup.find('sub', class_='plan-currency')\n",
        "    currency_unit = \"جنيه\"\n",
        "    if currency_unit_elem:\n",
        "        currency_text = currency_unit_elem.get_text(strip=True)\n",
        "        if \"جنيه\" in currency_text:\n",
        "            currency_unit = \"جنيه\"\n",
        "\n",
        "    for tab_id, category in tabs.items():\n",
        "        tab_section = soup.find('div', id=tab_id)\n",
        "        if not tab_section:\n",
        "            print(f\"Tab '{tab_id}' not found.\")\n",
        "            continue\n",
        "\n",
        "        description_p = tab_section.find('p', class_='mt-30 ff-suissintl-light fs-16')\n",
        "        description = description_p.get_text(strip=True) if description_p else \"\"\n",
        "\n",
        "        package_group = {\n",
        "            \"title\": tab_titles[category],\n",
        "            \"description\": description,\n",
        "            \"items\": []\n",
        "        }\n",
        "\n",
        "        # From tables\n",
        "        tables = tab_section.find_all('table')\n",
        "        for table in tables:\n",
        "            rows = table.find_all('tr')\n",
        "            if len(rows) < 2:\n",
        "                continue\n",
        "            name_row, data_row = rows[0], rows[1]\n",
        "            name_cells = name_row.find_all('td')\n",
        "            data_cells = data_row.find_all('td')\n",
        "            for name_cell, data_cell in zip(name_cells, data_cells):\n",
        "                try:\n",
        "                    name_elem = name_cell.find('h5', class_='plan-name')\n",
        "                    price_elem = name_cell.find('h5', class_='plan-price')\n",
        "                    if name_elem and price_elem:\n",
        "                        name = name_elem.get_text(strip=True).replace('\\n', ' ').strip()\n",
        "                        price = clean_numeric_value(price_elem.get_text(strip=True))\n",
        "                        data_value = data_cell.get_text(strip=True)\n",
        "                        data_gb = clean_numeric_value(data_value)\n",
        "\n",
        "                        package_group[\"items\"].append({\n",
        "                            \"name\": name,\n",
        "                            \"data_gb\": f\"{data_gb} {data_unit}\",\n",
        "                            \"price_egp\": f\"{price} {currency_unit}\",\n",
        "                            \"note\": dynamic_note\n",
        "                        })\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        # From cards\n",
        "        cards = tab_section.find_all('div', class_='card')\n",
        "        for card in cards:\n",
        "            name_elem = card.find('h5', class_='plan-name')\n",
        "            price_elem = card.find('h5', class_='plan-price')\n",
        "            data_elem = card.find('p', class_='ff-suissintl-bold.fs-16')\n",
        "            if name_elem and price_elem and data_elem:\n",
        "                try:\n",
        "                    name = name_elem.get_text(strip=True).replace('\\n', ' ').strip()\n",
        "                    price = clean_numeric_value(price_elem.get_text(strip=True))\n",
        "                    data_gb = clean_numeric_value(data_elem.get_text(strip=True))\n",
        "                    package_group[\"items\"].append({\n",
        "                        \"name\": name,\n",
        "                        \"data_gb\": f\"{data_gb} {data_unit}\",\n",
        "                        \"price_egp\": f\"{price} {currency_unit}\",\n",
        "                        \"note\": dynamic_note\n",
        "                    })\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        result[\"packages\"][category] = package_group\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Extract Extra Bundles\n",
        "# =============================\n",
        "def extract_extra_bundles():\n",
        "    extra_section = soup.find('section', id='for_textContainer')\n",
        "    if not extra_section:\n",
        "        return {}\n",
        "\n",
        "    title_div = extra_section.find('div', class_='for__sectionTitles')\n",
        "    titles = title_div.find_all('h3') if title_div else []\n",
        "    section_title = ' '.join([t.get_text(strip=True) for t in titles]) or \"الباقات الإضافية\"\n",
        "\n",
        "    description_p = extra_section.find('p', class_='fs-16')\n",
        "    description = description_p.get_text(strip=True) if description_p else \"\"\n",
        "\n",
        "    bundles = []\n",
        "    cards = extra_section.select(\".col-sm-12.col-md-6.col-lg-3.my-2.my-lg-0 .text-container\")\n",
        "\n",
        "    for card in cards:\n",
        "        name_elem = card.find('h5', class_='extra-name')\n",
        "        data_elem = card.find('h6', class_='extra-price')\n",
        "        price_elem = card.find('h6', class_='ff-suissintl-bold')\n",
        "\n",
        "        if name_elem and data_elem and price_elem:\n",
        "            try:\n",
        "                name = name_elem.get_text(strip=True)\n",
        "                data_gb = clean_numeric_value(data_elem.get_text(strip=True).split()[0])\n",
        "                price_egp = clean_numeric_value(price_elem.get_text(strip=True).split()[0])\n",
        "\n",
        "                bundles.append({\n",
        "                    \"name\": name,\n",
        "                    \"data_gb\": f\"{data_gb} جيجابايت\",\n",
        "                    \"price_egp\": f\"{price_egp} جنيه\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing bundle: {e}\")\n",
        "                continue\n",
        "\n",
        "    return {\n",
        "        \"section_title\": section_title,\n",
        "        \"description\": description,\n",
        "        \"bundles\": bundles\n",
        "    }\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Extract Emerald Offers\n",
        "# =============================\n",
        "def extract_emerald_offers():\n",
        "    emerald_section = None\n",
        "    for sec in soup.find_all('section', id='for_table'):\n",
        "        h3s = sec.find_all('h3')\n",
        "        titles = [h.get_text(strip=True) for h in h3s]\n",
        "        if any(\"فقط لعملاء أميريلد\" in t for t in titles):\n",
        "            emerald_section = sec\n",
        "            break\n",
        "\n",
        "    if not emerald_section:\n",
        "        return {}\n",
        "\n",
        "    # Get plan names\n",
        "    header_row = emerald_section.find('tr', style=lambda s: 'height' in str(s))\n",
        "    if not header_row:\n",
        "        return {}\n",
        "\n",
        "    plan_names = [\n",
        "        td.find('h5', class_='plan-name').get_text(strip=True) if td.find('h5', class_='plan-name') else f\"Plan {i+1}\"\n",
        "        for i, td in enumerate(header_row.find_all('td'))\n",
        "    ]\n",
        "\n",
        "    # Get offer rows\n",
        "    offer_rows = emerald_section.find_all('tr')[1:]\n",
        "\n",
        "    emerald_offers = []\n",
        "    for idx, row in enumerate(offer_rows):\n",
        "        offers = [td.get_text(strip=True) for td in row.find_all('td')]\n",
        "        emerald_offers.append({\n",
        "            \"plan\": plan_names[idx],\n",
        "            \"offers\": offers\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"section_title\": \"فقط لعملاء أميريلد\",\n",
        "        \"section_subtitle\": \"استمتع بخصومات حصرية على باقات ال eHome DSL\",\n",
        "        \"emerald_offers\": emerald_offers\n",
        "    }\n",
        "\n",
        "\n",
        "# =============================\n",
        "# ✅ New Function: Extract Service Features\n",
        "# =============================\n",
        "def extract_service_features():\n",
        "    features_section = soup.find('section', id='for_features_and_terms')\n",
        "\n",
        "    if not features_section:\n",
        "        return {\n",
        "            \"section_title\": \"مميزات الخدمة\",\n",
        "            \"description\": \"\",\n",
        "            \"features\": []\n",
        "        }\n",
        "\n",
        "    # Try to find the title block inside for__sectionTitles\n",
        "    title_div = features_section.find('div', class_='for__sectionTitles')\n",
        "    if title_div:\n",
        "        titles = title_div.find_all('h3')\n",
        "        section_title = ''.join([t.get_text(strip=True) for t in titles])\n",
        "    else:\n",
        "        section_title = \"مميزات الخدمة\"\n",
        "\n",
        "    # Description is empty in current HTML\n",
        "    description = \"\"\n",
        "\n",
        "    # Extract feature items from div.col-sm-12.col-md-6.col-lg-4.my-3\n",
        "    feature_items = features_section.select(\".col-sm-12.col-md-6.col-lg-4.my-3\")\n",
        "    features = []\n",
        "\n",
        "    for item in feature_items:\n",
        "        p_tag = item.find('p', class_=False)  # Get <p> without class\n",
        "        if p_tag:\n",
        "            text = p_tag.get_text(strip=True)\n",
        "\n",
        "            # Extract number manually if it starts with a digit\n",
        "            first_word = text.split()[0]\n",
        "            if first_word.isdigit():\n",
        "                number = first_word\n",
        "                clean_text = text[len(number):].strip()\n",
        "            else:\n",
        "                number = \"\"\n",
        "                clean_text = text\n",
        "\n",
        "            features.append({\n",
        "                \"number\": number,\n",
        "                \"text\": clean_text\n",
        "            })\n",
        "\n",
        "    return {\n",
        "        \"section_title\": section_title,\n",
        "        \"description\": description,\n",
        "        \"features\": features\n",
        "    }\n",
        "\n",
        "#----------\n",
        "#\n",
        "#--------------\n",
        "\n",
        "# Helper function to extract only digits from a string\n",
        "def clean_numeric_value(value):\n",
        "    \"\"\"Extract digits from a string.\"\"\"\n",
        "    return ''.join(filter(str.isdigit, value))\n",
        "\n",
        "# Function to extract extra packages\n",
        "def extract_extra_packages():\n",
        "    # Extract data unit dynamically\n",
        "    data_unit_elem = soup.find('small', class_='extra-currency')\n",
        "    data_unit = \"جيجابايت\"  # fallback\n",
        "    if data_unit_elem:\n",
        "        data_text = data_unit_elem.get_text(strip=True)\n",
        "        if \"جيجابايت\" in data_text:\n",
        "            data_unit = \"جيجابايت\"\n",
        "\n",
        "    # Extract price unit dynamically\n",
        "    price_unit_elem = soup.find('h6', class_='ff-suissintl-bold')\n",
        "    price_unit = \"جنيه\"  # fallback\n",
        "    if price_unit_elem:\n",
        "        price_sub = price_unit_elem.find('sub', class_='plan-currency')\n",
        "        if price_sub:\n",
        "            currency_text = price_sub.get_text(strip=True)\n",
        "            if \"جنيه\" in currency_text:\n",
        "                price_unit = \"جنيه\"\n",
        "\n",
        "    # Find extra packages section\n",
        "    extra_packages_section = soup.find('section', id='for_textContainer')\n",
        "    if not extra_packages_section:\n",
        "        return {\"description\": \"\", \"packages\": []}\n",
        "\n",
        "    description_p = extra_packages_section.find('p', class_='fs-16')\n",
        "    description = description_p.get_text(strip=True) if description_p else \"\"\n",
        "\n",
        "    cards = extra_packages_section.select(\".col-sm-12.col-md-6.col-lg-3.my-2.my-lg-0 .text-container\")\n",
        "    packages = []\n",
        "\n",
        "    for card in cards:\n",
        "        name_elem = card.find('h5', class_='extra-name')\n",
        "        data_elem = card.find('h6', class_='extra-price')\n",
        "        price_elem = card.find('h6', class_='ff-suissintl-bold')\n",
        "\n",
        "        if name_elem and data_elem and price_elem:\n",
        "            try:\n",
        "                name = name_elem.get_text(strip=True)\n",
        "                data_raw = data_elem.get_text(strip=True)\n",
        "                price_raw = price_elem.get_text(strip=True)\n",
        "\n",
        "                data_value = clean_numeric_value(data_raw.split()[0])\n",
        "                price_value = clean_numeric_value(price_raw.split()[0])\n",
        "\n",
        "                packages.append({\n",
        "                    \"name\": name,\n",
        "                    \"data_gb\": f\"{data_value} {data_unit}\",\n",
        "                    \"price_egp\": f\"{price_value} {price_unit}\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing package: {e}\")\n",
        "                continue\n",
        "\n",
        "    return {\n",
        "        \"description\": description,\n",
        "        \"packages\": packages\n",
        "    }\n",
        "\n",
        "# Function to extract terms and conditions for extra packages\n",
        "def extract_extra_packages_terms_and_conditions():\n",
        "    # Find all sections with id=\"for_features_and_terms\"\n",
        "    terms_sections = soup.find_all('section', id='for_features_and_terms')\n",
        "\n",
        "    for section in terms_sections:\n",
        "        title_div = section.find('div', class_='for__sectionTitles')\n",
        "        if not title_div:\n",
        "            continue\n",
        "\n",
        "        titles = title_div.find_all('h3')\n",
        "        full_title = ''.join([t.get_text(strip=True) for t in titles])\n",
        "\n",
        "        # Look for \"للباقة الإضافية\" or \"للباقة الاضافية\" (both forms exist in HTML)\n",
        "        if \"للباقة الإضافية\" in full_title or \"للباقة الاضافية\" in full_title:\n",
        "            items = section.select(\".col-sm-12.col-md-6.col-lg-4.my-3.d-flex\")\n",
        "            terms = []\n",
        "\n",
        "            for item in items:\n",
        "                span = item.find('span')\n",
        "                p_tag = item.find('p', class_='fs-16')\n",
        "                if span and p_tag:\n",
        "                    number = span.get_text(strip=True)\n",
        "                    text = p_tag.get_text(strip=True)\n",
        "                    terms.append({\n",
        "                        \"number\": number,\n",
        "                        \"text\": text\n",
        "                    })\n",
        "\n",
        "            return {\n",
        "                \"section_title\": \"الشروط و الاحكام للباقة الإضافية\",\n",
        "                \"terms\": terms\n",
        "            }\n",
        "\n",
        "    # Fallback\n",
        "    return {\n",
        "        \"section_title\": \"الشروط و الاحكام للباقة الإضافية\",\n",
        "        \"terms\": []\n",
        "    }\n",
        "\n",
        "# Run all extractions\n",
        "dsl_packages = extract_dsl_packages()\n",
        "terms_conditions = extract_terms_and_conditions()\n",
        "favorite_packages = extract_favorite_packages()\n",
        "extra_bundles = extract_extra_bundles()\n",
        "emerald_offers = extract_emerald_offers()\n",
        "service_features = extract_service_features()  # ✅ Added here\n",
        "#extra_packages_data = extract_extra_packages()\n",
        "extra_packages_terms_data = extract_extra_packages_terms_and_conditions()\n",
        "\n",
        "# Build final JSON output\n",
        "output = {\n",
        "    \"service_features\": service_features , # ✅ Add extracted service features\n",
        "    \"title\": title,\n",
        "    \"packages\": dsl_packages,\n",
        "    \"terms_and_conditions\": terms_conditions,\n",
        "    \"favorite_packages\": favorite_packages[\"packages\"],\n",
        "    \"extra_bundles\": extra_bundles,\n",
        "     #\"extra_packages\": extra_packages_data,\n",
        "    \"extra_packages_terms_and_conditions\": extra_packages_terms_data,\n",
        "    \"emerald_offers\": emerald_offers,\n",
        "}\n",
        "\n",
        "\n",
        "# Save to JSON file\n",
        "with open(\"full_ehome_dsl_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(output, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"✅ Data successfully extracted and saved to full_ehome_dsl_data.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sK5FAqUfeKE3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}