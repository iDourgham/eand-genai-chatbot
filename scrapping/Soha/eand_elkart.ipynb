{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b563909",
   "metadata": {},
   "source": [
    "#### Cards grouped by tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import json\n",
    "import time\n",
    "\n",
    "# === 1. Setup Selenium ===\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.eand.com.eg/StaticFiles/portal2/etisalat/pages/plans/elkart_prepaid.html\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# === 2. Parse full HTML with BeautifulSoup ===\n",
    "html = driver.page_source\n",
    "driver.quit()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# === 3. Extract tab names & their container mappings ===\n",
    "tab_map = {}\n",
    "buttons = soup.select(\"div.tabs-buttons button\")\n",
    "for btn in buttons:\n",
    "    target = btn.get(\"data-target\")\n",
    "    text = btn.get_text(strip=True)\n",
    "    if target == \"akwa_tab\":\n",
    "        tab_map[\"Cards_tab\"] = text\n",
    "    elif target == \"flat_tab\":\n",
    "        tab_map[\"Cards_tab2\"] = text\n",
    "    elif target == \"daily_tab\":\n",
    "        tab_map[\"Cards_tab3\"] = text\n",
    "    elif target == \"menu_tab\":\n",
    "        tab_map[\"Cards_tab4\"] = text\n",
    "\n",
    "# === 4. Loop through each tab container ===\n",
    "final_data = {}\n",
    "\n",
    "for container_id, tab_name in tab_map.items():\n",
    "    container = soup.select_one(f'#{container_id} > div > section > div > div')\n",
    "    if not container:\n",
    "        print(f\"⚠️ Skipping {container_id} — not found.\")\n",
    "        continue\n",
    "\n",
    "    cards = container.select(\"div.item\")\n",
    "    tab_cards = []\n",
    "\n",
    "    for card in cards:\n",
    "        try:\n",
    "            # Plan Name (fallback to \"\")\n",
    "            name_tag = card.select_one(\"h5.plan-name\")\n",
    "            plan_name = name_tag.get_text(strip=True) if name_tag else \"\"\n",
    "\n",
    "            # Price\n",
    "            price_tag = card.select_one(\"h5.plan-price\")\n",
    "            price = price_tag.get_text(strip=True).replace(\" \", \"\") if price_tag else \"\"\n",
    "\n",
    "            # Details as flat key-value (label: value)\n",
    "            detail_dict = {}\n",
    "            for li in card.select(\"li.list-group-item\"):\n",
    "                label_tag = li.select_one(\"small\")\n",
    "                value_tag = li.select_one(\"p.fs-16\")\n",
    "\n",
    "                label = label_tag.get_text(strip=True).replace(\" \", \"\") if label_tag else \"\"\n",
    "                value = value_tag.get_text(strip=True).replace(\" \", \"\") if value_tag else \"\"\n",
    "                if label or value:\n",
    "                    detail_dict[label] = value\n",
    "\n",
    "            tab_cards.append({\n",
    "                \"price\": price,\n",
    "                \"plan_name\": plan_name,\n",
    "                \"details\": detail_dict\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing a card: {e}\")\n",
    "\n",
    "    final_data[tab_name] = tab_cards\n",
    "\n",
    "# === 5. Save to JSON ===\n",
    "with open(\"cards_grouped_by_tab.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved data to 'cards_grouped_by_tab.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ed667",
   "metadata": {},
   "source": [
    "#### Cards with terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import json\n",
    "import time\n",
    "\n",
    "# === SETUP ===\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.eand.com.eg/StaticFiles/portal2/etisalat/pages/plans/elkart_prepaid.html\"\n",
    "driver.get(url)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# === Extract tab buttons and map to container IDs ===\n",
    "tab_map = {\n",
    "    \"akwa_tab\": \"Cards_tab\",\n",
    "    \"flat_tab\": \"Cards_tab2\",\n",
    "    \"daily_tab\": \"Cards_tab3\",\n",
    "    \"menu_tab\": \"Cards_tab4\"\n",
    "}\n",
    "\n",
    "# Get button name text for mapping\n",
    "tab_titles = {}\n",
    "buttons = driver.find_elements(By.CSS_SELECTOR, \".tabs-buttons button\")\n",
    "for btn in buttons:\n",
    "    key = btn.get_attribute(\"data-target\")\n",
    "    name = btn.text.strip()\n",
    "    if key in tab_map:\n",
    "        tab_titles[tab_map[key]] = {\n",
    "            \"btn_element\": btn,\n",
    "            \"title\": name\n",
    "        }\n",
    "\n",
    "final_data = {}\n",
    "\n",
    "# === LOOP through tabs ===\n",
    "for container_id, tab_info in tab_titles.items():\n",
    "    tab_name = tab_info[\"title\"]\n",
    "    btn = tab_info[\"btn_element\"]\n",
    "\n",
    "    # Click the tab to activate it and load its terms\n",
    "    driver.execute_script(\"arguments[0].click();\", btn)\n",
    "    time.sleep(2)  # Wait for content and terms to update\n",
    "\n",
    "    # Parse current HTML snapshot\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # ==== Scrape offers ====\n",
    "    container = soup.select_one(f'#{container_id} > div > section > div > div')\n",
    "    cards = container.select(\"div.item\") if container else []\n",
    "    tab_cards = []\n",
    "\n",
    "    for card in cards:\n",
    "        try:\n",
    "            # Plan Name (fallback to \"\")\n",
    "            name_tag = card.select_one(\"h5.plan-name\")\n",
    "            plan_name = name_tag.get_text(strip=True) if name_tag else \"\"\n",
    "\n",
    "            # Price\n",
    "            price_tag = card.select_one(\"h5.plan-price\")\n",
    "            price = price_tag.get_text(strip=True).replace(\" \", \"\") if price_tag else \"\"\n",
    "\n",
    "            # Details as flat key-value\n",
    "            detail_dict = {}\n",
    "            for li in card.select(\"li.list-group-item\"):\n",
    "                label_tag = li.select_one(\"small\")\n",
    "                value_tag = li.select_one(\"p.fs-16\")\n",
    "\n",
    "                label = label_tag.get_text(strip=True).replace(\" \", \"\") if label_tag else \"\"\n",
    "                value = value_tag.get_text(strip=True).replace(\" \", \"\") if value_tag else \"\"\n",
    "\n",
    "                if label or value:\n",
    "                    detail_dict[label] = value\n",
    "\n",
    "            tab_cards.append({\n",
    "                \"price\": price,\n",
    "                \"plan_name\": plan_name,\n",
    "                \"details\": detail_dict\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing a card in {tab_name}: {e}\")\n",
    "\n",
    "    # ==== Scrape Terms and Conditions ====\n",
    "    terms = []\n",
    "    terms_section = soup.select(\"#Terms .row.text-container.white-readAbout-sec.box-shadow\")\n",
    "    if terms_section:\n",
    "        for block in terms_section[0].select(\"div.col-sm-12\"):\n",
    "            text = block.select_one(\"p\")\n",
    "            if text:\n",
    "                terms.append(text.get_text(strip=True))\n",
    "\n",
    "    # ==== Save into final data ====\n",
    "    final_data[tab_name] = {\n",
    "        \"offers\": tab_cards,\n",
    "        \"الشروط والاحكام\": terms\n",
    "    }\n",
    "\n",
    "# === Export to JSON ===\n",
    "with open(\"cards_with_terms.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"All cards and terms saved to 'cards_with_terms.json'\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab00a8c",
   "metadata": {},
   "source": [
    "#### Full Page Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab54a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import json\n",
    "import time\n",
    "\n",
    "# === SETUP SELENIUM ===\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.eand.com.eg/StaticFiles/portal2/etisalat/pages/plans/elkart_prepaid.html\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# === EXTRACT PAGE TITLE & DESCRIPTION ===\n",
    "page_title = driver.find_element(By.XPATH, \".//h1[@class='GESSTwoBold_font fs-25 mb-3 ']\").text.strip()\n",
    "page_description = driver.find_element(By.XPATH, \".//p[@class='fs-14 grey-color ']\").text.strip()\n",
    "\n",
    "# === MAP TAB BUTTONS TO CONTAINER IDs ===\n",
    "tab_map = {\n",
    "    \"akwa_tab\": \"Cards_tab\",\n",
    "    \"flat_tab\": \"Cards_tab2\",\n",
    "    \"daily_tab\": \"Cards_tab3\",\n",
    "    \"menu_tab\": \"Cards_tab4\"\n",
    "}\n",
    "\n",
    "tab_titles = {}\n",
    "buttons = driver.find_elements(By.CSS_SELECTOR, \".tabs-buttons button\")\n",
    "for btn in buttons:\n",
    "    key = btn.get_attribute(\"data-target\")\n",
    "    name = btn.text.strip()\n",
    "    if key in tab_map:\n",
    "        tab_titles[tab_map[key]] = {\n",
    "            \"btn_element\": btn,\n",
    "            \"title\": name\n",
    "        }\n",
    "\n",
    "# === COLLECT ALL DATA ===\n",
    "final_data = {\n",
    "    \"page_title\": page_title,\n",
    "    \"page_description\": page_description,\n",
    "    \"الانظمة\": {}\n",
    "}\n",
    "\n",
    "for container_id, tab_info in tab_titles.items():\n",
    "    tab_name = tab_info[\"title\"]\n",
    "    btn = tab_info[\"btn_element\"]\n",
    "\n",
    "    # Click tab and wait for content and terms to load\n",
    "    driver.execute_script(\"arguments[0].click();\", btn)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Get updated HTML snapshot\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # === EXTRACT OFFERS ===\n",
    "    container = soup.select_one(f'#{container_id} > div > section > div > div')\n",
    "    cards = container.select(\"div.item\") if container else []\n",
    "    tab_cards = []\n",
    "\n",
    "    for card in cards:\n",
    "        try:\n",
    "            plan_name_tag = card.select_one(\"h5.plan-name\")\n",
    "            plan_name = plan_name_tag.get_text(strip=True) if plan_name_tag else \"\"\n",
    "\n",
    "            price_tag = card.select_one(\"h5.plan-price\")\n",
    "            price = price_tag.get_text(strip=True).replace(\" \", \"\") if price_tag else \"\"\n",
    "\n",
    "            details = {}\n",
    "            for li in card.select(\"li.list-group-item\"):\n",
    "                label_tag = li.select_one(\"small\")\n",
    "                value_tag = li.select_one(\"p.fs-16\")\n",
    "\n",
    "                label = label_tag.get_text(strip=True).replace(\" \", \"\") if label_tag else \"\"\n",
    "                value = value_tag.get_text(strip=True).replace(\" \", \"\") if value_tag else \"\"\n",
    "\n",
    "                if label or value:\n",
    "                    details[label] = value\n",
    "\n",
    "            tab_cards.append({\n",
    "                \"price\": price,\n",
    "                \"plan_name\": plan_name,\n",
    "                \"details\": details\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing a card in {tab_name}: {e}\")\n",
    "\n",
    "    # === EXTRACT TERMS ===\n",
    "    terms = []\n",
    "    terms_section = soup.select(\"#Terms .row.text-container.white-readAbout-sec.box-shadow\")\n",
    "    if terms_section:\n",
    "        for block in terms_section[0].select(\"div.col-sm-12\"):\n",
    "            text = block.select_one(\"p\")\n",
    "            if text:\n",
    "                terms.append(text.get_text(strip=True))\n",
    "\n",
    "    final_data[\"الانظمة\"][tab_name] = {\n",
    "        \"offers\": tab_cards,\n",
    "        \"الشروط والاحكام\": terms\n",
    "    }\n",
    "\n",
    "# === EXPORT TO JSON ===\n",
    "with open(\"akwa_full_page.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Data saved to 'akwa_full_page.json'\")\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
